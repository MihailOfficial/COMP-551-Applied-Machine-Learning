{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNDT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neural_network(input_shape):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def train_neural_decision_tree(X_train, y_train, X_test, y_test):\n",
    "    # Neural network part\n",
    "    nn_model = build_neural_network((X_train.shape[1],))\n",
    "    nn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    nn_model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "    # Get intermediate output from neural network\n",
    "    intermediate_layer_model = tf.keras.models.Model(inputs=nn_model.input,\n",
    "                                                     outputs=nn_model.layers[-2].output)\n",
    "    intermediate_output_train = intermediate_layer_model.predict(X_train)\n",
    "    intermediate_output_test = intermediate_layer_model.predict(X_test)\n",
    "\n",
    "    # Decision tree part\n",
    "    tree_model = DecisionTreeClassifier()\n",
    "    tree_model.fit(intermediate_output_train, y_train)\n",
    "    \n",
    "    # Prediction and evaluation\n",
    "    y_pred = tree_model.predict(intermediate_output_test)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 4ms/step - loss: 9.2602 - accuracy: 0.0500 \n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 6.4649 - accuracy: 0.5167\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 6.0393 - accuracy: 0.6417\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 5.7439 - accuracy: 0.6750\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 0s/step - loss: 5.4660 - accuracy: 0.6833\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 172us/step - loss: 5.2032 - accuracy: 0.6833\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 5.0170 - accuracy: 0.6833\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 4.9066 - accuracy: 0.6833\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4.8320 - accuracy: 0.6833\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 4.7758 - accuracy: 0.6750\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Load the Iris dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "column_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"]\n",
    "iris_data = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Preprocess the data\n",
    "X = iris_data.drop(\"class\", axis=1)\n",
    "y = iris_data[\"class\"]\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2)\n",
    "\n",
    "# Train the model and evaluate its accuracy\n",
    "accuracy = train_neural_decision_tree(X_train, y_train, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haberman's Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 2ms/step - loss: 7.0753 - accuracy: 0.1762 \n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 4.6580 - accuracy: 0.7008\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8218 - accuracy: 0.7336\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9661 - accuracy: 0.7500\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.7541\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5928 - accuracy: 0.7582\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7582\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7623\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5378 - accuracy: 0.7582\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 429us/step - loss: 0.5261 - accuracy: 0.7541\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.7258064516129032\n"
     ]
    }
   ],
   "source": [
    "# Load the Haberman's Survival dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/haberman/haberman.data\"\n",
    "column_names = [\"age\", \"year_of_operation\", \"positive_axillary_nodes\", \"survival_status\"]\n",
    "haberman_data = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Preprocess the data\n",
    "X = haberman_data.drop(\"survival_status\", axis=1)\n",
    "y = haberman_data[\"survival_status\"]\n",
    "# Adjust labels to start from 0\n",
    "y = y - 1\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)\n",
    "\n",
    "# Train the model and evaluate its accuracy\n",
    "accuracy = train_neural_decision_tree(X_train, y_train, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 1s 2ms/step - loss: 2.3928 - accuracy: 0.6006\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 1.0293 - accuracy: 0.7229\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 0s 862us/step - loss: 0.8732 - accuracy: 0.8473\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 1.9445 - accuracy: 0.6563\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.0591 - accuracy: 0.6404\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.4263 - accuracy: 0.5260\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.3097 - accuracy: 0.5528\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.0464 - accuracy: 0.6288\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.2083 - accuracy: 0.5825\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.8597 - accuracy: 0.3951\n",
      "44/44 [==============================] - 0s 766us/step\n",
      "11/11 [==============================] - 0s 855us/step\n",
      "Accuracy: 0.8497109826589595\n"
     ]
    }
   ],
   "source": [
    "# Load the Car Evaluation dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\"\n",
    "column_names = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
    "car_data = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Preprocess the data: One-hot encode categorical features\n",
    "X = car_data.drop(\"class\", axis=1)\n",
    "y = car_data[\"class\"]\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "X_encoded = one_hot_encoder.fit_transform(X).toarray()\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2)\n",
    "\n",
    "# Train the model and evaluate its accuracy\n",
    "accuracy = train_neural_decision_tree(X_train, y_train, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast Cancer Wisconsin (Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 0s 754us/step - loss: 8.0064 - accuracy: 0.4258\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 722us/step - loss: 3.1516 - accuracy: 0.9123\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 727us/step - loss: 2.7506 - accuracy: 0.9535\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 716us/step - loss: 2.6940 - accuracy: 0.9589\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 693us/step - loss: 2.5981 - accuracy: 0.9678\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 779us/step - loss: 2.5919 - accuracy: 0.9678\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 770us/step - loss: 2.5597 - accuracy: 0.9678\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 749us/step - loss: 2.5508 - accuracy: 0.9553\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 795us/step - loss: 2.4923 - accuracy: 0.9589\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 749us/step - loss: 2.5030 - accuracy: 0.9589\n",
      "18/18 [==============================] - 0s 432us/step\n",
      "5/5 [==============================] - 0s 554us/step\n",
      "Accuracy: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "# Load the Breast Cancer Wisconsin (Original) dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\"\n",
    "column_names = [\"Sample code number\", \"Clump Thickness\", \"Uniformity of Cell Size\", \"Uniformity of Cell Shape\",\n",
    "                \"Marginal Adhesion\", \"Single Epithelial Cell Size\", \"Bare Nuclei\", \"Bland Chromatin\",\n",
    "                \"Normal Nucleoli\", \"Mitoses\", \"Class\"]\n",
    "cancer_data = pd.read_csv(url, names=column_names)\n",
    "\n",
    "# Preprocess the data\n",
    "# Drop the 'Sample code number' as it's not a feature\n",
    "cancer_data.drop([\"Sample code number\"], axis=1, inplace=True)\n",
    "\n",
    "# Replace missing values denoted by '?' with NaN and then impute\n",
    "cancer_data.replace(\"?\", np.nan, inplace=True)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "cancer_data = pd.DataFrame(imputer.fit_transform(cancer_data), columns=cancer_data.columns)\n",
    "\n",
    "X = cancer_data.drop(\"Class\", axis=1)\n",
    "y = cancer_data[\"Class\"]\n",
    "\n",
    "# Encode the labels (2 for benign, 4 for malignant) to 0 and 1\n",
    "y_encoded = y.replace({2: 0, 4: 1})\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2)\n",
    "\n",
    "# Train the model and evaluate its accuracy\n",
    "accuracy = train_neural_decision_tree(X_train, y_train, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pima Indians Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 1s 2ms/step - loss: 2.7498 - accuracy: 0.4251 \n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7299 - accuracy: 0.7459\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7573\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7687\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7704\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7671\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7850\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7818\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7850\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7980\n",
      "20/20 [==============================] - 0s 790us/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Load the Pima Indians Diabetes dataset\n",
    "diabetes_data = pd.read_csv('./datasets/diabetes.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "# Replace zeros in certain columns with NaN and then impute\n",
    "columns_to_impute = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "diabetes_data[columns_to_impute] = diabetes_data[columns_to_impute].replace(0, np.nan)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "diabetes_data[columns_to_impute] = imputer.fit_transform(diabetes_data[columns_to_impute])\n",
    "\n",
    "X = diabetes_data.drop(\"Outcome\", axis=1)\n",
    "y = diabetes_data[\"Outcome\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)\n",
    "\n",
    "# Train the model and evaluate its accuracy\n",
    "accuracy = train_neural_decision_tree(X_train, y_train, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poker Hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 1s 740us/step - loss: 1.9310 - accuracy: 0.4875\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 1s 801us/step - loss: 1.8242 - accuracy: 0.5154\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 1s 712us/step - loss: 2.5727 - accuracy: 0.5285\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 1s 708us/step - loss: 3.4655 - accuracy: 0.4995\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 1s 703us/step - loss: 3.4655 - accuracy: 0.4995\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 1s 698us/step - loss: 3.4655 - accuracy: 0.4995\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 1s 698us/step - loss: 3.4655 - accuracy: 0.4995\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 1s 710us/step - loss: 3.4655 - accuracy: 0.4995\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 1s 702us/step - loss: 3.4655 - accuracy: 0.4995\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 1s 720us/step - loss: 3.4655 - accuracy: 0.4995\n",
      "782/782 [==============================] - 0s 364us/step\n",
      "31250/31250 [==============================] - 10s 320us/step\n",
      "Accuracy: 0.453695\n"
     ]
    }
   ],
   "source": [
    "# Load the Poker Hand dataset\n",
    "url_train = \"https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-training-true.data\"\n",
    "url_test = \"https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-testing.data\"\n",
    "column_names = [\"Suit1\", \"Card1\", \"Suit2\", \"Card2\", \"Suit3\", \"Card3\", \"Suit4\", \"Card4\", \"Suit5\", \"Card5\", \"Class\"]\n",
    "poker_data_train = pd.read_csv(url_train, names=column_names)\n",
    "poker_data_test = pd.read_csv(url_test, names=column_names)\n",
    "\n",
    "# Preprocess the data: One-hot encode categorical features\n",
    "X_train = poker_data_train.drop(\"Class\", axis=1)\n",
    "y_train = poker_data_train[\"Class\"]\n",
    "X_test = poker_data_test.drop(\"Class\", axis=1)\n",
    "y_test = poker_data_test[\"Class\"]\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "X_train_encoded = one_hot_encoder.fit_transform(X_train).toarray()\n",
    "X_test_encoded = one_hot_encoder.transform(X_test).toarray()\n",
    "\n",
    "# Train the model and evaluate its accuracy\n",
    "accuracy = train_neural_decision_tree(X_train_encoded, y_train, X_test_encoded, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statlog (German Credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 0s 710us/step - loss: 2.5563 - accuracy: 0.5263\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 678us/step - loss: 0.7060 - accuracy: 0.7075\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 675us/step - loss: 0.5837 - accuracy: 0.7063\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 704us/step - loss: 0.5151 - accuracy: 0.7088\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 764us/step - loss: 0.4975 - accuracy: 0.7063\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 759us/step - loss: 0.4701 - accuracy: 0.7138\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 758us/step - loss: 0.4487 - accuracy: 0.7113\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 733us/step - loss: 0.4287 - accuracy: 0.7125\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 774us/step - loss: 0.4152 - accuracy: 0.7125\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 742us/step - loss: 0.4131 - accuracy: 0.7150\n",
      "25/25 [==============================] - 0s 408us/step\n",
      "7/7 [==============================] - 0s 514us/step\n",
      "Accuracy: 0.755\n"
     ]
    }
   ],
   "source": [
    "# Load the German Credit dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
    "column_names = [\"Status of existing checking account\", \"Duration in month\", \"Credit history\", \n",
    "                \"Purpose\", \"Credit amount\", \"Savings account/bonds\", \"Present employment since\", \n",
    "                \"Installment rate in percentage of disposable income\", \"Personal status and sex\", \n",
    "                \"Other debtors / guarantors\", \"Present residence since\", \"Property\", \n",
    "                \"Age in years\", \"Other installment plans\", \"Housing\", \"Number of existing credits at this bank\", \n",
    "                \"Job\", \"Number of people being liable to provide maintenance for\", \"Telephone\", \n",
    "                \"Foreign worker\", \"Credit risk\"]\n",
    "credit_data = pd.read_csv(url, names=column_names, sep=' ', header=None)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = [\"Status of existing checking account\", \"Credit history\", \"Purpose\", \"Savings account/bonds\", \n",
    "                    \"Present employment since\", \"Personal status and sex\", \"Other debtors / guarantors\", \n",
    "                    \"Property\", \"Other installment plans\", \"Housing\", \"Job\", \"Telephone\", \"Foreign worker\"]\n",
    "numerical_cols = [\"Duration in month\", \"Credit amount\", \"Installment rate in percentage of disposable income\", \n",
    "                  \"Present residence since\", \"Age in years\", \"Number of existing credits at this bank\", \n",
    "                  \"Number of people being liable to provide maintenance for\"]\n",
    "\n",
    "# Preprocess the data\n",
    "X = credit_data.drop(\"Credit risk\", axis=1)\n",
    "y = credit_data[\"Credit risk\"]\n",
    "\n",
    "# Create a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(), categorical_cols)\n",
    "    ])\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2)\n",
    "\n",
    "# Train the model and evaluate its accuracy\n",
    "accuracy = train_neural_decision_tree(X_train, y_train, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1689/1689 [==============================] - 3s 1ms/step - loss: 1.0714 - accuracy: 0.2414\n",
      "Epoch 2/10\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 1.0986 - accuracy: 0.2461\n",
      "Epoch 3/10\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 1.0986 - accuracy: 0.2461\n",
      "Epoch 4/10\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 1.0986 - accuracy: 0.2461\n",
      "Epoch 5/10\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 1.0986 - accuracy: 0.2461\n",
      "Epoch 6/10\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 1.0986 - accuracy: 0.2461\n",
      "Epoch 7/10\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 1.0986 - accuracy: 0.2461\n",
      "Epoch 8/10\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 1.0986 - accuracy: 0.2461\n",
      "Epoch 9/10\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 1.0986 - accuracy: 0.2461\n",
      "Epoch 10/10\n",
      "1689/1689 [==============================] - 2s 1ms/step - loss: 1.0986 - accuracy: 0.2461\n",
      "1689/1689 [==============================] - 2s 1ms/step\n",
      "423/423 [==============================] - 1s 1ms/step\n",
      "Accuracy: 0.6649644760213144\n"
     ]
    }
   ],
   "source": [
    "# Load the Connect-4 dataset\n",
    "path_to_dataset = './datasets/connect-4.csv'\n",
    "column_names = [\"C\"+str(i) for i in range(1, 43)] + [\"Class\"]\n",
    "connect4_data = pd.read_csv(path_to_dataset, names=column_names, header=None)\n",
    "\n",
    "# Preprocess the data: One-hot encode categorical features\n",
    "X = connect4_data.drop(\"Class\", axis=1)\n",
    "y = connect4_data[\"Class\"]\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "X_encoded = one_hot_encoder.fit_transform(X).toarray()\n",
    "\n",
    "# Encode the labels using LabelEncoder from scikit-learn\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model and evaluate its accuracy\n",
    "accuracy = train_neural_decision_tree(X_train, y_train, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 8.3564 - accuracy: 0.2012\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 6.7408 - accuracy: 0.4085\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 5.7669 - accuracy: 0.5427\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 457us/step - loss: 4.2955 - accuracy: 0.5976\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 537us/step - loss: 3.7014 - accuracy: 0.6220\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.7491 - accuracy: 0.5915\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 2.4359 - accuracy: 0.5061\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 2.1847 - accuracy: 0.4939\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 0s/step - loss: 2.0940 - accuracy: 0.5366\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 706us/step - loss: 1.9685 - accuracy: 0.5488\n",
      "6/6 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.7317073170731707\n"
     ]
    }
   ],
   "source": [
    "# Load the Image Segmentation dataset\n",
    "path_to_dataset = './datasets/segmentation_train.csv'\n",
    "column_names = [\"Class\", \"Region-centroid-col\", \"Region-centroid-row\", \"Region-pixel-count\", \"Short-line-density-5\", \n",
    "                \"Short-line-density-2\", \"Vedge-mean\", \"Vegde-sd\", \"Hedge-mean\", \"Hedge-sd\", \"Intensity-mean\", \n",
    "                \"Rawred-mean\", \"Rawblue-mean\", \"Rawgreen-mean\", \"Exred-mean\", \"Exblue-mean\", \"Exgreen-mean\", \n",
    "                \"Value-mean\", \"Saturation-mean\", \"Hue-mean\"]\n",
    "segmentation_data = pd.read_csv(path_to_dataset, names=column_names, header=None, skiprows=5)\n",
    "\n",
    "# Preprocess the data\n",
    "X = segmentation_data.drop(\"Class\", axis=1)\n",
    "y = segmentation_data[\"Class\"]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2)\n",
    "\n",
    "# Train the model and evaluate its accuracy\n",
    "accuracy = train_neural_decision_tree(X_train, y_train, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covrtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14526/14526 [==============================] - 18s 1ms/step - loss: 2.8946 - accuracy: 0.1493\n",
      "Epoch 2/10\n",
      "14526/14526 [==============================] - 17s 1ms/step - loss: 3.4091 - accuracy: 0.0157\n",
      "Epoch 3/10\n",
      "14526/14526 [==============================] - 17s 1ms/step - loss: 3.4092 - accuracy: 0.0157\n",
      "Epoch 4/10\n",
      "14526/14526 [==============================] - 17s 1ms/step - loss: 3.4092 - accuracy: 0.0157\n",
      "Epoch 5/10\n",
      "14526/14526 [==============================] - 17s 1ms/step - loss: 3.4092 - accuracy: 0.0157\n",
      "Epoch 6/10\n",
      "14526/14526 [==============================] - 16s 1ms/step - loss: 3.4092 - accuracy: 0.0157\n",
      "Epoch 7/10\n",
      "14526/14526 [==============================] - 17s 1ms/step - loss: 3.4092 - accuracy: 0.0157\n",
      "Epoch 8/10\n",
      "14526/14526 [==============================] - 17s 1ms/step - loss: 3.4092 - accuracy: 0.0157\n",
      "Epoch 9/10\n",
      "14526/14526 [==============================] - 17s 1ms/step - loss: 3.4092 - accuracy: 0.0157\n",
      "Epoch 10/10\n",
      "14526/14526 [==============================] - 17s 1ms/step - loss: 3.4092 - accuracy: 0.0157\n",
      "14526/14526 [==============================] - 12s 847us/step\n",
      "3632/3632 [==============================] - 3s 805us/step\n",
      "Accuracy: 0.8263125736857052\n"
     ]
    }
   ],
   "source": [
    "# Load the Covertype dataset\n",
    "path_to_dataset = './datasets/covtype.csv'\n",
    "column_names = [f'feature_{i}' for i in range(1, 55)]\n",
    "covertype_data = pd.read_csv(path_to_dataset, names=column_names)\n",
    "\n",
    "# Preprocess the data\n",
    "# Assuming the last column is the target variable\n",
    "X = covertype_data.iloc[:, :-1]\n",
    "y = covertype_data.iloc[:, -1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model and evaluate its accuracy\n",
    "accuracy = train_neural_decision_tree(X_train, y_train, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
